下面给你一套**可直接落地**、覆盖 EVM 链（以 Uniswap v2 / v3 为代表，也适用于 SushiSwap、PancakeSwap 等 v2/v3 兼容 DEX）的两阶段完整方案：

* **阶段 A｜链上 DEX 数据采集与落盘**

  * A1 方案：**自己建索引器（JSON‑RPC `eth_getLogs` + 事件 ABI 解码）**
  * A2 方案：**The Graph 子图（GraphQL）**，快速起步或做基准校验
  * A3 方案：**准实时订阅（WebSocket `eth_subscribe: logs`）**
* **阶段 B｜数据清洗、统一 Schema、指标构建与 K 线聚合**

  * 价格/成交量/费率推导、1m/5m/1h K 线、数据质量（缺块/重组）与增量更新

> 关键依据（部分）：
>
> * **以事件日志为核心**：EVM 的日志/事件可通过 `eth_getLogs` 批量拉取，需按提供商限制**分块查询**（常见限制 10,000 区块一段），也可使用过滤器/订阅实时接收。([QuickNode][1])
> * **Uniswap v2**：`Factory.PairCreated` 事件枚举交易对；`Pair.Swap` 事件给出 `amount0In/Out, amount1In/Out`；`Sync` 更新储备。官方文档列出事件签名与部署地址。([Uniswap Docs][2])
> * **Uniswap v3**：`Factory.PoolCreated` 列出池与费档；`Pool.Swap` 事件给出 `amount0/amount1`（带符号）、`sqrtPriceX96`、`liquidity`、`tick`。([Uniswap Docs][3])
> * **The Graph**：Uniswap 官方子图可直接查到 pool/pair、swap、volume 等（注意有**索引延迟**，不是“即时上链数据”）。([Uniswap Docs][4])
> * **实时订阅**：`eth_subscribe: logs` 在链重组时可能重复/撤回（`removed: true`），必须处理幂等与回滚。([MetaMask][5])

---

## 一、工程总览

**数据入口（Connectors）**

* **自建索引器**（推荐主路径）：直接连节点（Alchemy / Infura / QuickNode / Ankr / 自建节点等）→ 通过 `eth_getLogs` 按事件 `topic0` + 地址过滤，分块拉全量历史；准实时用 `eth_subscribe: logs` 或轮询 filter。
* **The Graph**（备选 / 校验）：GraphQL 快速拉数据，用于对照与冷启动（有延迟，非权威最终值）。([Uniswap Docs][4])

**统一 Schema（核心表）**

* `tokens(token, symbol, decimals, chain_id)`
* `pools(pool, dex, version, token0, token1, fee, created_at_block)`
* `swaps(tx_hash, log_index, pool, block_number, block_time, trader, amount0, amount1, price, usd_price0?, usd_price1?)`
* `liquidity_snapshots(pool, block_number, reserve0, reserve1, liquidity?, tick?)`（v2 用 `Sync`，v3 可用状态字段）

**存储**：开发用 **Parquet + DuckDB**；生产建议 **PostgreSQL/TimescaleDB** + **对象存储（Parquet 分区）**。

**重组与确认**：默认**延后 N=12 区块**确认后再标记“confirmed”，实时订阅收到 `removed=true` 要回滚。([MetaMask][5])

---

## 二、阶段 A｜链上 DEX 数据采集（端到端）

### A0. 环境与项目骨架

```bash
# Python 3.10+
python -m venv venv && source venv/bin/activate
pip install -U web3 eth-abi hexbytes pandas pyarrow duckdb tqdm tenacity python-dotenv pydantic requests
```

```
.
├─ conf/
│  └─ dex.yaml                 # 链/DEX/起始块配置
├─ data/
│  ├─ raw/                     # 原始事件落盘（parquet）
│  └─ clean/                   # 统一schema/聚合后
├─ scripts/
│  ├─ dex_indexer.py           # v2 / v3 历史索引（工况健壮）
│  ├─ live_subscribe.py        # 准实时订阅（日志）
│  └─ build_candles.py         # 从 swaps 生成 K 线
└─ .env                        # RPC_URL_ETHEREUM=..., RPC_URL_BSC=...
```

`conf/dex.yaml`（示例：以以太坊主网 Uniswap v2 & v3 为例）：

```yaml
chain_id: 1
rpc_url_env: RPC_URL_ETHEREUM
confirmations: 12
dexes:
  - name: uniswap-v2
    version: v2
    factory: "0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f"   # 官方文档地址
    start_block: 10000835
  - name: uniswap-v3
    version: v3
    factory: "0x1F98431c8aD98523631AE4a59f267346ea31F984"   # 官方文档地址
    start_block: 12369621
```

（v2/v3 工厂合约地址见官方部署页。([Uniswap Docs][6])）

---

### A1. 自建索引器（历史回补）：核心代码（含 v2/v3）

> 思路：
>
> 1. 先用 **Factory 事件**枚举交易对/池：v2 的 `PairCreated`，v3 的 `PoolCreated`。([Uniswap Docs][2])
> 2. 再按每个 pair/pool 地址批量拉 **Swap**（及可选 Mint/Burn/Sync）事件，**分块**处理（避开 10k 区块上限）。([QuickNode][1])
> 3. 解码后按 **token decimals** 归一到人类读数；v3 用 `sqrtPriceX96` 推导 mid‑price。([Uniswap Docs][7])
> 4. 补齐 **block timestamp**（区块时间）并落盘分区。

```python
# scripts/dex_indexer.py
import os, math, json, time, decimal
from decimal import Decimal
from dataclasses import dataclass
from typing import Iterable, List, Dict, Tuple

from web3 import Web3
from web3._utils.events import get_event_data
from hexbytes import HexBytes
from tqdm import tqdm
import pandas as pd
from tenacity import retry, wait_exponential, stop_after_attempt
from dotenv import load_dotenv
import yaml

load_dotenv()

# -------- ABIs（只保留所需事件/函数的最小子集） --------
ERC20_MIN_ABI = [
  {"constant":True,"inputs":[],"name":"decimals","outputs":[{"name":"","type":"uint8"}],"type":"function"},
  {"constant":True,"inputs":[],"name":"symbol","outputs":[{"name":"","type":"string"}],"type":"function"},
  {"constant":True,"inputs":[],"name":"name","outputs":[{"name":"","type":"string"}],"type":"function"},
]

V2_FACTORY_ABI = [{
  "anonymous": False,
  "inputs": [
    {"indexed": True, "internalType": "address", "name": "token0", "type": "address"},
    {"indexed": True, "internalType": "address", "name": "token1", "type": "address"},
    {"indexed": False,"internalType": "address", "name": "pair",   "type": "address"},
    {"indexed": False,"internalType": "uint256","name": "",       "type": "uint256"}
  ],
  "name": "PairCreated","type": "event"
}]

V2_PAIR_ABI = [{
  "anonymous": False,
  "inputs": [
    {"indexed": True,  "name": "sender",    "type": "address"},
    {"indexed": False, "name": "amount0In", "type": "uint256"},
    {"indexed": False, "name": "amount1In", "type": "uint256"},
    {"indexed": False, "name": "amount0Out","type": "uint256"},
    {"indexed": False, "name": "amount1Out","type": "uint256"},
    {"indexed": True,  "name": "to",        "type": "address"}
  ],
  "name": "Swap","type": "event"
},
{
  "anonymous": False,
  "inputs": [
    {"indexed": False,"name":"reserve0","type":"uint112"},
    {"indexed": False,"name":"reserve1","type":"uint112"}
  ],
  "name":"Sync","type":"event"
}]

V3_FACTORY_ABI = [{
  "anonymous": False,
  "inputs": [
    {"indexed": True,  "name": "token0","type": "address"},
    {"indexed": True,  "name": "token1","type": "address"},
    {"indexed": False, "name": "fee",   "type": "uint24"},
    {"indexed": False, "name": "tickSpacing","type":"int24"},
    {"indexed": False, "name": "pool",  "type": "address"}
  ],
  "name":"PoolCreated","type":"event"
}]

V3_POOL_ABI = [{
  "anonymous": False,
  "inputs": [
    {"indexed": True,  "name":"sender",       "type":"address"},
    {"indexed": True,  "name":"recipient",    "type":"address"},
    {"indexed": False, "name":"amount0",      "type":"int256"},
    {"indexed": False, "name":"amount1",      "type":"int256"},
    {"indexed": False, "name":"sqrtPriceX96", "type":"uint160"},
    {"indexed": False, "name":"liquidity",    "type":"uint128"},
    {"indexed": False, "name":"tick",         "type":"int24"}
  ],
  "name":"Swap","type":"event"
}]

# -------- 工具 --------
@dataclass
class CfgDEX:
    name: str; version: str; factory: str; start_block: int

def w3_from_env(env_key: str) -> Web3:
    url = os.environ[env_key]
    if url.startswith("ws"): return Web3(Web3.WebsocketProvider(url))
    return Web3(Web3.HTTPProvider(url))

@retry(wait=wait_exponential(multiplier=1, min=1, max=30), stop=stop_after_attempt(6))
def get_logs(w3: Web3, **flt):
    # 直接封装 w3.provider.make_request
    return w3.eth.get_logs(flt)

def chunk_ranges(start_block: int, end_block: int, step: int) -> Iterable[Tuple[int,int]]:
    cur = start_block
    while cur <= end_block:
        yield cur, min(end_block, cur+step-1)
        cur += step

def dynamic_get_logs(w3: Web3, address, topics, from_block, to_block, step_hint=5000):
    # 适配提供商的“区块跨度限制”（常见 10k），出现超限/超时自动减半步长重试。:contentReference[oaicite:11]{index=11}
    step = step_hint
    cur = from_block
    while cur <= to_block:
        hi = min(to_block, cur + step - 1)
        try:
            logs = get_logs(w3, address=address, topics=topics, fromBlock=cur, toBlock=hi)
            for lg in logs: yield lg
            cur = hi + 1
        except Exception as e:
            if step <= 50:  # 已很小仍失败，跳过该段避免死锁
                print(f"[WARN] getLogs failed @[{cur},{hi}] {e}")
                cur = hi + 1
            else:
                step = max(50, step // 2)

# 缓存区块时间
_block_time_cache: Dict[int,int] = {}
def block_time(w3: Web3, bn: int) -> int:
    t = _block_time_cache.get(bn)
    if t: return t
    ts = w3.eth.get_block(bn)["timestamp"]
    _block_time_cache[bn] = ts
    return ts

# ERC20 元数据
def token_meta(w3: Web3, token: str) -> Dict:
    c = w3.eth.contract(address=Web3.to_checksum_address(token), abi=ERC20_MIN_ABI)
    try:
        sym = c.functions.symbol().call()
    except Exception: sym = ""
    try:
        dec = c.functions.decimals().call()
    except Exception: dec = 18
    try:
        nam = c.functions.name().call()
    except Exception: nam = ""
    return {"symbol": sym, "decimals": int(dec), "name": nam}

# v3 价格: price(token1/token0)
Q96 = Decimal(2) ** 96
def price_v3_from_sqrtpx96(sqrtp: int) -> Decimal:
    # price = (sqrtPriceX96 / 2**96) ** 2
    x = Decimal(sqrtp) / Q96
    return x * x

# -------- 索引器主体 --------
def index_v2(w3: Web3, dex: CfgDEX, latest: int, confirmations: int):
    factory = Web3.to_checksum_address(dex.factory)
    factory_contract = w3.eth.contract(address=factory, abi=V2_FACTORY_ABI)
    pair_evt = factory_contract.events.PairCreated
    pair_topic0 = w3.keccak(text="PairCreated(address,address,address,uint256)").hex()

    start = dex.start_block
    safe_latest = latest - confirmations
    pairs = []
    print(f"[v2] Discover pairs from {start} to {safe_latest}")
    for lg in tqdm(dynamic_get_logs(w3, address=factory, topics=[pair_topic0], from_block=start, to_block=safe_latest)):
        data = get_event_data(w3.codec, pair_evt._get_event_abi(), lg)
        pairs.append({
            "pool": Web3.to_checksum_address(data["args"]["pair"]),
            "token0": Web3.to_checksum_address(data["args"]["token0"]),
            "token1": Web3.to_checksum_address(data["args"]["token1"]),
            "created_block": lg["blockNumber"]
        })
    pairs_df = pd.DataFrame(pairs).drop_duplicates("pool")
    os.makedirs("data/raw", exist_ok=True)
    pairs_df.to_parquet(f"data/raw/{dex.name}_pairs.parquet")
    print(f"[v2] pairs saved: {len(pairs_df)}")

    # 拉 Swap & Sync
    swap_evt_abi = [abi for abi in V2_PAIR_ABI if abi["name"]=="Swap"][0]
    sync_evt_abi = [abi for abi in V2_PAIR_ABI if abi["name"]=="Sync"][0]
    swap_topic0 = w3.keccak(text="Swap(address,uint256,uint256,uint256,uint256,address)").hex()
    sync_topic0 = w3.keccak(text="Sync(uint112,uint112)").hex()

    # token 元数据缓存
    meta_cache = {}

    rows = []
    # 分批地址（避免一次放太多）
    BATCH = 50
    addrs = pairs_df["pool"].tolist()
    for i in tqdm(range(0, len(addrs), BATCH), desc="v2 swaps"):
        batch = addrs[i:i+BATCH]
        for lg in dynamic_get_logs(w3, address=batch, topics=[swap_topic0], from_block=start, to_block=safe_latest):
            data = get_event_data(w3.codec, swap_evt_abi, lg)
            pool = Web3.to_checksum_address(lg["address"])
            # 获取 token0/1 与 decimals
            rec = pairs_df[pairs_df.pool==pool].iloc[0]
            for tk in ("token0","token1"):
                if rec[tk] not in meta_cache:
                    meta_cache[rec[tk]] = token_meta(w3, rec[tk])
            d0 = meta_cache[rec["token0"]]["decimals"]
            d1 = meta_cache[rec["token1"]]["decimals"]

            a0in  = Decimal(data["args"]["amount0In"])  / (Decimal(10) ** d0)
            a1in  = Decimal(data["args"]["amount1In"])  / (Decimal(10) ** d1)
            a0out = Decimal(data["args"]["amount0Out"]) / (Decimal(10) ** d0)
            a1out = Decimal(data["args"]["amount1Out"]) / (Decimal(10) ** d1)
            # 方向与价格（以 token1/token0 mid 估算：用成交换手计算）
            # 用输出/输入近似成交价（v2 没有 sqrtPrice，严格做需结合储备或前后 reserve）
            traded0 = a0in if a0in>0 else a0out
            traded1 = a1out if a1out>0 else a1in
            price   = (traded1 / traded0) if traded0 and traded1 else None
            rows.append({
                "dex": dex.name, "version": "v2", "pool": pool,
                "token0": rec["token0"], "token1": rec["token1"],
                "block_number": lg["blockNumber"], "block_time": block_time(w3, lg["blockNumber"]),
                "tx_hash": lg["transactionHash"].hex(), "log_index": lg["logIndex"],
                "amount0": float(a0in) * -1 if a0in>0 else float(a0out),
                "amount1": float(a1in) * -1 if a1in>0 else float(a1out),
                "price": float(price) if price else None
            })
    if rows:
        df = pd.DataFrame(rows)
        df.to_parquet(f"data/raw/{dex.name}_swaps.parquet")
        print(f"[v2] swaps saved: {len(df)}")

def index_v3(w3: Web3, dex: CfgDEX, latest: int, confirmations: int):
    factory = Web3.to_checksum_address(dex.factory)
    factory_contract = w3.eth.contract(address=factory, abi=V3_FACTORY_ABI)
    pc_evt = factory_contract.events.PoolCreated
    pc_topic0 = w3.keccak(text="PoolCreated(address,address,uint24,int24,address)").hex()

    start = dex.start_block
    safe_latest = latest - confirmations
    pools = []
    print(f"[v3] Discover pools from {start} to {safe_latest}")
    for lg in tqdm(dynamic_get_logs(w3, address=factory, topics=[pc_topic0], from_block=start, to_block=safe_latest)):
        data = get_event_data(w3.codec, pc_evt._get_event_abi(), lg)
        pools.append({
            "pool": Web3.to_checksum_address(data["args"]["pool"]),
            "token0": Web3.to_checksum_address(data["args"]["token0"]),
            "token1": Web3.to_checksum_address(data["args"]["token1"]),
            "fee": int(data["args"]["fee"]),
            "created_block": lg["blockNumber"]
        })
    pools_df = pd.DataFrame(pools).drop_duplicates("pool")
    os.makedirs("data/raw", exist_ok=True)
    pools_df.to_parquet(f"data/raw/{dex.name}_pools.parquet")
    print(f"[v3] pools saved: {len(pools_df)}")

    swap_evt_abi = [abi for abi in V3_POOL_ABI if abi["name"]=="Swap"][0]
    swap_topic0 = w3.keccak(text="Swap(address,address,int256,int256,uint160,uint128,int24)").hex()

    meta_cache = {}
    rows = []
    BATCH = 50
    addrs = pools_df["pool"].tolist()
    for i in tqdm(range(0, len(addrs), BATCH), desc="v3 swaps"):
        batch = addrs[i:i+BATCH]
        for lg in dynamic_get_logs(w3, address=batch, topics=[swap_topic0], from_block=start, to_block=safe_latest):
            data = get_event_data(w3.codec, swap_evt_abi, lg)
            pool = Web3.to_checksum_address(lg["address"])
            rec = pools_df[pools_df.pool==pool].iloc[0]
            for tk in ("token0","token1"):
                if rec[tk] not in meta_cache:
                    meta_cache[rec[tk]] = token_meta(w3, rec[tk])
            d0 = meta_cache[rec["token0"]]["decimals"]; d1 = meta_cache[rec["token1"]]["decimals"]

            a0 = Decimal(data["args"]["amount0"]) / (Decimal(10) ** d0)
            a1 = Decimal(data["args"]["amount1"]) / (Decimal(10) ** d1)
            sqrtp = int(data["args"]["sqrtPriceX96"])
            price = price_v3_from_sqrtpx96(sqrtp)  # token1/token0 mid price after swap
            rows.append({
                "dex": dex.name, "version": "v3", "pool": pool,
                "token0": rec["token0"], "token1": rec["token1"], "fee": rec["fee"],
                "block_number": lg["blockNumber"], "block_time": block_time(w3, lg["blockNumber"]),
                "tx_hash": lg["transactionHash"].hex(), "log_index": lg["logIndex"],
                "amount0": float(a0), "amount1": float(a1),
                "price": float(price)
            })
    if rows:
        df = pd.DataFrame(rows)
        df.to_parquet(f"data/raw/{dex.name}_swaps.parquet")
        print(f"[v3] swaps saved: {len(df)}")

def main():
    with open("conf/dex.yaml","r") as f:
        cfg = yaml.safe_load(f)
    w3 = w3_from_env(cfg["rpc_url_env"])
    latest = int(w3.eth.block_number)
    confs = int(cfg.get("confirmations", 12))
    for d in cfg["dexes"]:
        dex = CfgDEX(**d)
        if dex.version == "v2":
            index_v2(w3, dex, latest, confs)
        elif dex.version == "v3":
            index_v3(w3, dex, latest, confs)
        else:
            print("Unsupported version:", dex.version)

if __name__ == "__main__":
    # 提高 Decimal 精度，避免 v3 价格计算溢出
    decimal.getcontext().prec = 50
    main()
```

**说明与关键点**

* 使用 `eth_getLogs` 必须**分块**（很多服务商限制 10k 区块），示例实现了**动态步长**与重试。([QuickNode][1])
* v2 价格用“成交换手比”近似（精确方法可结合 `Sync` 前后储备或链下路由）。v3 价格可由事件里的 `sqrtPriceX96` 精确恢复（Q64.96 定点）为 **token1/token0** 中间价。([Uniswap Docs][7])
* 工厂事件枚举 pair/pool：v2 `PairCreated`，v3 `PoolCreated`。([Uniswap Docs][2])
* 代币元数据的 `decimals/symbol` 并非强制标准（但事实上的行业约定，OpenZeppelin 实现包含），因此做了容错。([OpenZeppelin Docs][8])

---

### A2. 用 The Graph 快速拉（可选/校验）

> 适合**快速验证**数据结构或做**基线**。官方提供 v2/v3 子图与查询示例。([Uniswap Docs][4])

**示例：按时间窗口拉 v3 的 swaps（GraphQL 片段）**

```graphql
query Swaps($pool: ID!, $ts: Int!) {
  swaps(first: 1000, orderBy: timestamp, orderDirection: asc,
        where: { pool: $pool, timestamp_gte: $ts }) {
    id
    transaction { id }
    timestamp
    recipient
    amount0
    amount1
    sqrtPriceX96
  }
}
```

> 注：子图**有索引延迟**、可能与链上最终状态存在短时偏差，不能替代“权威链上回补”。([Uniswap Docs][4])

---

### A3. 准实时订阅（WebSocket）

两种方式：

1. WebSocket `eth_subscribe: logs`（服务端推送，注意链重组会有 `removed:true` 回滚）。([MetaMask][5])
2. 轮询 filter（web3.py 自带）——实现简单、健壮性好。

**简化实现（WS 原生协议订阅 v3 Swap）**：

```python
# scripts/live_subscribe.py
import os, json, asyncio, websockets, time
from dotenv import load_dotenv
load_dotenv()

WS_URL = os.environ["RPC_URL_ETHEREUM_WS"]  # 需提供 WS 端点
# v3 Swap 的 topic0
from web3 import Web3
SWAP_V3_TOPIC0 = Web3.keccak(text="Swap(address,address,int256,int256,uint160,uint128,int24)").hex()

async def main():
    async with websockets.connect(WS_URL, ping_interval=20) as ws:
        sub_id = 1
        params = [{
            "address": [],  # 可填具体 pool 地址数组；为空则仅靠 topic 过滤
            "topics": [SWAP_V3_TOPIC0]
        }]
        await ws.send(json.dumps({"id": sub_id, "method": "eth_subscribe", "params": ["logs", *params], "jsonrpc":"2.0"}))
        resp = await ws.recv(); print("subscribed:", resp)
        while True:
            msg = json.loads(await ws.recv())
            if "params" in msg and "result" in msg["params"]:
                log = msg["params"]["result"]
                if log.get("removed"):  # 链重组撤回
                    # TODO: 从存储中回滚该 tx_hash + logIndex
                    continue
                # TODO: 解码 + 存盘；建议与历史索引共用解码函数
                print("log:", log["transactionHash"])
            await asyncio.sleep(0)

if __name__ == "__main__":
    asyncio.run(main())
```

> 订阅语义与重组行为见文档：日志会在重组时**撤回并重发**。([MetaMask][5])

---

## 三、阶段 B｜清洗与指标构建（含 K 线聚合）

### B1. 统一 schema 与落盘

上面 `dex_indexer.py` 已将 `pairs/pools` 与 `swaps` 分别落到 `data/raw/*_pairs.parquet`、`*_swaps.parquet`。下一步做统一清洗与分区。

```python
# scripts/build_candles.py
import pandas as pd, os, numpy as np

def build_candles(swaps_path: str, out_dir: str, rule: str="1T"):
    df = pd.read_parquet(swaps_path)
    df["dt"] = pd.to_datetime(df["block_time"], unit="s", utc=True)
    # 按 pool 聚合成 K 线
    res = []
    for pool, g in df.sort_values("dt").groupby("pool"):
        # price 为 token1/token0
        o = g.set_index("dt")["price"].resample(rule).first()
        h = g.set_index("dt")["price"].resample(rule).max()
        l = g.set_index("dt")["price"].resample(rule).min()
        c = g.set_index("dt")["price"].resample(rule).last()
        v0 = g.set_index("dt")["amount0"].abs().resample(rule).sum()
        v1 = g.set_index("dt")["amount1"].abs().resample(rule).sum()
        out = pd.DataFrame({
            "pool": pool, "open": o, "high": h, "low": l, "close": c,
            "vol_token0": v0, "vol_token1": v1
        }).dropna(subset=["open","high","low","close"])
        res.append(out.reset_index(names="datetime"))
    if not res: return
    out_df = pd.concat(res, ignore_index=True)
    os.makedirs(out_dir, exist_ok=True)
    out_df.to_parquet(os.path.join(out_dir, "candles_"+rule+".parquet"))
    print("candles saved:", len(out_df))

if __name__ == "__main__":
    # 例：对 v3 swaps 生成 1m K 线
    build_candles("data/raw/uniswap-v3_swaps.parquet", "data/clean", "1T")
```

**注意点**

* v2 的 `price` 用成交换手近似值；若需精确 mid‑price，可在同一块中结合 `Sync` 前后储备或直接读 `getReserves()`。([Uniswap Docs][9])
* v3 的 `price` 来自 `sqrtPriceX96`（事件已给出，精确）。([Uniswap Docs][7])

### B2. 数据质量与一致性

* **确认深度**：默认 12 块（以太坊常见实践），落盘时标记 `confirmed=true/false`；准实时订阅收到 `removed=true` 时回滚对应行。([MetaMask][5])
* **分块与幂等**：按 `(tx_hash, log_index)` 作为主键去重，确保重复写入可忽略。
* **提供商限制**：不同提供商的 `eth_getLogs` 区块跨度限制不同；通用做法是**动态缩步**且指数回退。([QuickNode][1])

### B3. 典型派生指标

* **池内即时中间价**：v3 用 `sqrtPriceX96`，v2 用 `reserve1/reserve0`；也可输出**tick**以便做区间流动性分析。([Uniswap Docs][7])
* **成交方向**：v2 看 `amount?In/Out`；v3 看 `amount0/amount1` 的**符号**（负为流出、正为流入），这一语义由官方事件定义。([Uniswap Docs][7])
* **池/代币维度的 1m/5m/1h K 线**、**日成交量/费收入**（v2 费率通常为 0.3%，v3 按 fee tier 0.01%/0.05%/0.3%/1% 等）；fee tier 见 v3 `PoolCreated.fee`。([Uniswap Docs][3])

---

## 四、可选：用 The Graph 快速校验/补数

* Uniswap 官方子图给出了**查询样例**（如某日的 volume、池当前流动性、position 费用等）。([Uniswap Docs][10])
* 每个版本/网络有对应入口与 Explorer 页面。([Uniswap Docs][4])

---

## 五、端到端执行步骤（从 0 到可分析）

1. **准备 RPC 与配置**

   * 在 `.env` 写 `RPC_URL_ETHEREUM=...`（HTTP），如需实时订阅再加 `RPC_URL_ETHEREUM_WS=...`（WebSocket）。
   * 按需修改 `conf/dex.yaml` 的 `factory`、`start_block`（v2/v3 官方部署地址见文档）。([Uniswap Docs][6])

2. **历史回补（索引器）**

   ```bash
   python scripts/dex_indexer.py
   ```

   产出：`data/raw/uniswap-v2_pairs.parquet` / `uniswap-v2_swaps.parquet` / `uniswap-v3_pools.parquet` / `uniswap-v3_swaps.parquet`

   * 程序会**分块调用** `eth_getLogs` 避免超限（常见 10k 块限制）。([QuickNode][1])

3. **准实时订阅（可选）**

   ```bash
   export RPC_URL_ETHEREUM_WS=...
   python scripts/live_subscribe.py
   ```

   订阅 `logs` 并处理 `removed:true` 回滚。([MetaMask][5])

4. **构建 K 线与指标**

   ```bash
   python scripts/build_candles.py
   ```

   生成 `data/clean/candles_1T.parquet`（池维度 1m K 线）。

5. **查询/分析（DuckDB 简例）**

   ```sql
   -- 近24h 成交量Top池
   SELECT pool, sum(vol_token1) AS vol1
   FROM read_parquet('data/clean/candles_1T.parquet')
   WHERE datetime >= now() - INTERVAL 1 day
   GROUP BY 1 ORDER BY 2 DESC LIMIT 20;
   ```

---

## 六、扩展与注意事项

* **多链**：BSC/Polygon/Arbitrum/Optimism 只需切换 `RPC_URL_*` 与 `factory` 地址（官方部署页或相应区块浏览器确认）。([Uniswap Docs][11])
* **费率与 USD 归一**：可引入稳定币对（USDC/USDT）的价格或 Chainlink 喂价换算 USD。
* **性能**：

  * 批量缓存 `block_number → timestamp`；
  * 地址分批（如 50 个 pool 一次）；
  * 结果**分区落盘**（按 `chain/dex/pool/YYYYMM`）以加速增量处理。
* **合规**：遵守各节点服务商的速率/使用条款；The Graph 数据**非最终上链事实**，以链上事件为准。([Uniswap Docs][4])

---

## 关键参考（与你代码直接相关）

* `eth_getLogs`/过滤器与**区块跨度限制**（需分块）与调用教程。([QuickNode][1])
* `eth_subscribe: logs` 的**重组/撤回**语义。([MetaMask][5])
* **Uniswap v2**：Factory/Pair 文档（`PairCreated`、`Swap`/`Sync` 事件）；v2 交换概念与接口。([Uniswap Docs][2])
* **Uniswap v3**：Factory `PoolCreated`；Pool 事件 `Swap`（含 `amount0/amount1/sqrtPriceX96` 等字段定义）。([Uniswap Docs][3])
* **The Graph**：Uniswap 官方子图与 v3 查询示例。([Uniswap Docs][4])

