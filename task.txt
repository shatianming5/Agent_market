Σ╕ïΘ¥óτ╗ÖΣ╜áΣ╕ÇσÑù**σÅ»τ¢┤µÄÑΦÉ╜σ£░**τÜäΣ╕ñΘÿ╢µ«╡µû╣µíê∩╝Ü
A) σèáσ»åΦ┤ºσ╕ü∩╝êcrypto∩╝ëµò░µì«τÜä**Σ╕ïΦ╜╜Σ╕ÄσñäτÉåσà¿µ╡üτ¿ï**∩╝êσÉ½Σ╕ñτºìσÅ»Θ¥áµò░µì«µ║ÉΣ╕ÄσÅ»σñìτö¿µá╕σ┐âΣ╗úτáü∩╝ë∩╝¢
B) τö¿µ╕àµ┤ùσÉÄτÜäµò░µì«Φ┐¢Φíî**Σ╕Ñµá╝σÅ»σñìτÄ░τÜäσ¢₧µ╡ïµ₧äσ╗║**∩╝êσÉ½Σ║ñµÿôµêÉµ£¼/µ╗æτé╣/µ¡óµìƒµ¡óτ¢ê/σÅéµò░µÉ£τ┤ó/Φ╡░µá╖Θ¬îΦ»ü∩╝ë∩╝îσÉîµá╖τ╗Öσç║µá╕σ┐âΣ╗úτáüΣ╕ÄµëºΦíîµ¡ÑΘ¬ñπÇé

> Φ»┤µÿÄ∩╝ÜΣ╜áσåÖτÜäΓÇ£cryptroΓÇ¥µêæτÉåΦºúΣ╕║ ΓÇ£crypto∩╝êσèáσ»åΦ┤ºσ╕ü∩╝ëΓÇ¥πÇéΦïÑΣ╜áσÅªµ£ëµëÇµîç∩╝îσÅ»σåìσæèΦ»ëµêæπÇé

---

## µÇ╗ΦºêΣ╕ÄΘÇëσ₧ï∩╝êσèíσ«₧σÅ»Φíî∩╝ë

**µò░µì«µ¥Ñµ║ÉΣ╕ñµ¥íΦ╖»Θâ╜σÅ»Φíî∩╝îσ╗║Φ««σ╣╢Φíî∩╝Ü**

1. **σ«₧µù╢/Φ┐æσ«₧µù╢µïëσÅû**∩╝Üτö¿ `CCXT` τ╗ƒΣ╕ÇΣ╗ÄΣ║ñµÿôµëÇ∩╝êσªé BinanceπÇüOKXπÇüBybit τ¡ë∩╝ëµïëσÅû K τ║┐∩╝êOHLCV∩╝ëπÇé`fetch_ohlcv(symbol, timeframe, since, limit)` τ╗ƒΣ╕ÇΦ┐öσ¢₧ `[timestamp, open, high, low, close, volume]`∩╝îµù╢Θù┤µê│µ»½τºÆπÇüµîëµù╢Θù┤σìçσ║ÅµÄÆσêù∩╝¢µ£ÇσÉÄΣ╕Çµá╣µ¡úσ£¿σ╜óµêÉτÜä K τ║┐σÅ»Φâ╜Σ╕ìσ«îµò┤∩╝êΘ£ÇΦ┐çµ╗ñ/µáçµ│¿∩╝ëπÇéΦ┐Öµÿ» CCXT σ«ÿµû╣µëïσåîµÿÄτí«τÜäτ║ªσ«ÜπÇé([CCXT Documentation][1])

2. **µë╣ΘçÅσÄåσÅ▓µò░µì«**∩╝ÜBinance σ«ÿµû╣σà¼σ╝ÇΣ╗ôσ║ô∩╝êBinance Data Collection / data.binance.vision∩╝ëµÅÉΣ╛¢**µùÑ/µîëµ£ê**µëôσîàτÜä K τ║┐ CSV/ZIP∩╝êσ╣╢σ╕ªµ£ë `CHECKSUM` σ«îµò┤µÇºµáíΘ¬î∩╝ë∩╝¢Φç¬ 2025-01-01 Φ╡╖ **τÄ░Φ┤ºµò░µì«µù╢Θù┤µê│Σ╕║σ╛«τºÆτ║º**∩╝îΦºúµ₧Éµù╢Φªüτë╣σê½σñäτÉåπÇéσ«ÿµû╣ README µÿÄτí«Σ║åτ¢«σ╜òΣ╕Äµù╢Θù┤µê│σÅÿµ¢┤πÇé([GitHub][2])

**σ¢₧µ╡ïσ╝òµôÄ**∩╝ÜΘççτö¿ `vectorbt`∩╝êNumba/NumPy σÉæΘçÅσîû∩╝îΘÇƒσ║ªΣ╕ÄσÅ»µë⌐σ▒òµÇºΘâ╜Σ╕ìΘöÖ∩╝ë∩╝î`Portfolio.from_signals` σÄƒτöƒµö»µîüΣ║ñµÿôΦ┤╣τÄçπÇüµ╗æτé╣πÇüµ¡óµìƒ/µ¡óτ¢ê/Φ┐╜Φ╕¬µ¡óµìƒτ¡ëσÅéµò░∩╝¢µûçµíúµÿÄτí«ΓÇ£σ«₧τÄ░µ¡óµìƒΣ╕Äµ¡óτ¢êΘÇÇσç║ΓÇ¥πÇé([VectorBT][3])

**Σ║ñµÿôµêÉµ£¼σƒ║σçå**∩╝ÜBinance τÄ░Φ┤º**Θ╗ÿΦ«ñµëïτ╗¡Φ┤╣τ║ª 0.1%**∩╝êτ¡ëτ║ºπÇüµÿ»σÉªτö¿ BNB µè╡µëúτ¡ëΣ╝Üσ╜▒σôì∩╝ë∩╝¢σ£¿σ¢₧µ╡ïσÅéµò░ΘçîΣ╜£Σ╕║**σÅ»Φ░â**∩╝êΣ╛ïσªé `fees=0.001`∩╝ëπÇéΦ┤╣τÄçΣ╗Ñσ«ÿµû╣Φ┤╣τÄçΘí╡/FAQΣ╕║σçåπÇé([Binance][4])

---

# Θÿ╢µ«╡ A∩╝Üµò░µì«Σ╕ïΦ╜╜Σ╕ÄσñäτÉå∩╝êτ½»σê░τ½»∩╝ë

### A0. τÄ»σóâ&Θí╣τ¢«Θ¬¿µ₧╢

```bash
# σ╗║Φ«« Python 3.10+
python -m venv venv && source venv/bin/activate  # Windows τö¿ venv\Scripts\activate
pip install -U ccxt pandas polars pyarrow duckdb tqdm tenacity python-dateutil requests vectorbt pandas_ta

# Θí╣τ¢«τ╗ôµ₧ä∩╝êσ╗║Φ««∩╝ë
.
Γö£ΓöÇ conf/
Γöé  ΓööΓöÇ symbols.yaml        # Σ║ñµÿôµëÇ/σôüτºì/σæ¿µ£ƒΘàìτ╜«
Γö£ΓöÇ data/
Γöé  ΓööΓöÇ raw/                # σÄƒσºïΦÉ╜τ¢ÿ∩╝êparquet/csv∩╝ë
Γöé  ΓööΓöÇ clean/              # µ╕àµ┤ùσÉÄΦÉ╜τ¢ÿ∩╝êparquet∩╝îµîëσêåσî║∩╝ë
Γö£ΓöÇ scripts/
Γöé  Γö£ΓöÇ fetch_ccxt_ohlcv.py
Γöé  Γö£ΓöÇ fetch_binance_bulk.py
Γöé  Γö£ΓöÇ clean_ohlcv.py
Γöé  ΓööΓöÇ dq_report.py        # µò░µì«Φ┤¿ΘçÅµúÇµƒÑµèÑσæè∩╝êσÅ»ΘÇë∩╝ë
ΓööΓöÇ backtests/
   ΓööΓöÇ vbt_ma_rsi.py
```

`symbols.yaml` τñ║Σ╛ï∩╝Ü

```yaml
exchange: binance
type: spot
symbols: ["BTC/USDT", "ETH/USDT"]
timeframes: ["1m", "5m", "1h"]
start: "2019-01-01"
end: null     # Σ╕║τ⌐║Φí¿τñ║µïëσê░µ£Çµû░
store_as: "parquet"
```

---

### A1. µû╣µíê A∩╝êCCXT µïëσÅû∩╝ëµá╕σ┐âΣ╗úτáü

> Φªüτé╣∩╝ÜµáíΘ¬îΣ║ñµÿôµëÇµÿ»σÉªµö»µîüΦ»Ñ `timeframe`∩╝¢σêåΘí╡µèôσÅû∩╝ê`limit` ΘÇÜσ╕╕σê░ 1000∩╝ë∩╝¢Σ╕Ñµá╝Θü┐ΘçìπÇüΘÇƒτÄçΘÖÉσê╢πÇüµû¡τé╣τ╗¡Σ╝á∩╝¢µ£ÇσÉÄΣ╕Çµá╣µ£¬µö╢ K τ║┐σëöΘÖñµêûµáçΦ«░πÇé`fetch_ohlcv` τÜäΦíîΣ╕║Σ╕Äσ¡ùµ«╡Θí║σ║ÅΦºü CCXT µëïσåîπÇé([CCXT Documentation][1])

```python
# scripts/fetch_ccxt_ohlcv.py
import os, math, time, json
from datetime import datetime, timezone
from dateutil.parser import isoparse

import ccxt
import pandas as pd
from tenacity import retry, wait_exponential, stop_after_attempt

def timeframe_to_ms(tf: str) -> int:
    unit = tf[-1].lower()
    n = int(tf[:-1])
    if unit == 'm': return n * 60_000
    if unit == 'h': return n * 60 * 60_000
    if unit == 'd': return n * 24 * 60 * 60_000
    if unit == 'w': return n * 7 * 24 * 60 * 60_000
    raise ValueError(f"Unsupported timeframe: {tf}")

def ensure_dir(p): os.makedirs(p, exist_ok=True)

def ccxt_exchange(exchange_id: str, type_: str = 'spot'):
    klass = getattr(ccxt, exchange_id)
    ex = klass({'enableRateLimit': True, 'options': {'defaultType': type_}})
    ex.load_markets()
    return ex

@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(8))
def _fetch_page(ex, symbol, timeframe, since, limit):
    # σ╛êσñÜΣ║ñµÿôµëÇ limit=1000∩╝¢µ£ëτÜäµö»µîü endTime/τ¢┤σê░σÅéµò░∩╝îΦ┐ÖΘçîΣ┐¥µîüσà╝σ«╣
    return ex.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=limit)

def fetch_ohlcv_range(exchange_id: str, type_: str, symbol: str, timeframe: str,
                      start: str, end: str | None, out_path: str, limit: int = 1000):
    ex = ccxt_exchange(exchange_id, type_)
    if timeframe not in ex.timeframes:
        raise ValueError(f"{exchange_id} Σ╕ìµö»µîü timeframe={timeframe}∩╝îσÅ»τö¿∩╝Ü{list(ex.timeframes.keys())}")

    # Φºúµ₧Éµù╢Θù┤
    start_ms = int(isoparse(start).replace(tzinfo=timezone.utc).timestamp() * 1000)
    end_ms = int(isoparse(end).replace(tzinfo=timezone.utc).timestamp() * 1000) if end else int(time.time() * 1000)

    tf_ms = timeframe_to_ms(timeframe)
    all_rows = []
    since = start_ms

    print(f"[{exchange_id}] {symbol} {timeframe} Σ╗Ä {start} σê░ {('now' if end is None else end)} µïëσÅûΓÇª")

    while since < end_ms:
        batch = _fetch_page(ex, symbol, timeframe, since, limit)
        if not batch:
            break
        all_rows.extend(batch)
        last_ts = batch[-1][0]
        # Θÿ▓Θçì∩╝ÜΣ╕ïΣ╕ÇΘí╡Σ╗ÄΣ╕ïΣ╕Çµá╣Kτ║┐σ╝Çσºï
        since = last_ts + tf_ms
        # ΘÇƒτÄçΘÖÉσê╢
        if hasattr(ex, 'rateLimit') and ex.rateLimit:
            time.sleep(ex.rateLimit / 1000)

    if not all_rows:
        print("µùáµò░µì«Φ┐öσ¢₧")
        return

    # OHLCV: [ts, o, h, l, c, v]∩╝êµ»½τºÆ∩╝îσìçσ║Å∩╝ë
    df = pd.DataFrame(all_rows, columns=["timestamp","open","high","low","close","volume"])
    # Φ┐çµ╗ñµ£¬µö╢K∩╝Üµ£ÇσÉÄΣ╕Çµá╣σªéµ₧£µù╢Θù┤ >= end_ms - tf_ms∩╝îΣ┐¥σ«êσëöΘÖñ
    cutoff = end_ms - tf_ms
    df = df[df["timestamp"] <= cutoff].copy()

    # σÄ╗Θçì/µÄÆσ║Å/τ┤óσ╝ò
    df = df.drop_duplicates(subset=["timestamp"]).sort_values("timestamp")
    df["datetime"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)
    df = df.set_index("datetime").drop(columns=["timestamp"])
    # σ╝║τ▒╗σ₧ï
    for col in ["open","high","low","close","volume"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    ensure_dir(os.path.dirname(out_path))
    df.to_parquet(out_path, engine="pyarrow")
    print(f"Σ┐¥σ¡ÿσê░ {out_path}∩╝îσà▒ {len(df)} Φíî")

if __name__ == "__main__":
    import argparse, yaml
    p = argparse.ArgumentParser()
    p.add_argument("--conf", default="conf/symbols.yaml")
    args = p.parse_args()
    cfg = yaml.safe_load(open(args.conf, "r"))

    for sym in cfg["symbols"]:
        for tf in cfg["timeframes"]:
            out_dir = f"data/raw/exchange={cfg['exchange']}/type={cfg.get('type','spot')}/symbol={sym.replace('/','-')}/tf={tf}"
            name = f"{sym.replace('/','-')}-{tf}-{cfg['start']}_to_{(cfg['end'] or 'now')}.parquet"
            out_path = os.path.join(out_dir, name)
            fetch_ohlcv_range(cfg["exchange"], cfg.get("type","spot"), sym, tf, cfg["start"], cfg["end"], out_path)
```

> σñçµ│¿∩╝ÜΣ╕ìσÉîΣ║ñµÿôµëÇτÜä `limit`πÇüσêåΘí╡τ╗åΦèéπÇüµÿ»σÉªΦ┐öσ¢₧µ£¬µö╢ K τ¡ëσ¡ÿσ£¿σ╖«σ╝é∩╝îΦ┐Öµÿ»τñ╛σî║σ╕╕ΦºüΘù«Θóÿ∩╝¢σ╛¬τÄ»σêåΘí╡µÿ»σ«ÿµû╣µëïσåîσ╗║Φ««τÜäσüÜµ│òπÇé([GitHub][5])

---

### A2. µû╣µíê B∩╝êBinance µë╣ΘçÅ ZIP/CSV∩╝ëµá╕σ┐âΣ╗úτáü

> Σ╝ÿτé╣∩╝Ü**σÄåσÅ▓σà¿ΘçÅ**Σ╕ïΦ╜╜µ¢┤σ┐½µ¢┤σ«îµò┤πÇüσÅ»τö¿ `CHECKSUM` µáíΘ¬î∩╝¢Θ£Çµ│¿µäÅ**2025-01-01 Φ╡╖τÄ░Φ┤º K τ║┐µù╢Θù┤µê│Σ╕║σ╛«τºÆ**∩╝ê`open time / close time`∩╝ëσ╣╢σ£¿Φºúµ₧Éµù╢µ¡úτí«µìóτ«ùπÇé([GitHub][2])

```python
# scripts/fetch_binance_bulk.py
import os, io, zipfile, requests, hashlib
from datetime import date
import pandas as pd

BASE = "https://data.binance.vision/data/spot/{freq}/klines/{symbol}/{interval}/"
# freq: daily / monthly

def ensure_dir(p): os.makedirs(p, exist_ok=True)

def download(url: str) -> bytes:
    r = requests.get(url, timeout=60)
    r.raise_for_status()
    return r.content

def verify_checksum(zip_bytes: bytes, checksum_txt: str) -> bool:
    sha256 = hashlib.sha256(zip_bytes).hexdigest().upper()
    # CHECKSUM µûçΣ╗╢σåàσ«╣σ╜óσªé∩╝Ü"SHA256 (FILENAME) = <HEX>"
    return sha256 in checksum_txt.upper()

def parse_kline_csv(csv_bytes: bytes, micros: bool) -> pd.DataFrame:
    # CSV σêù∩╝Üopen time, open, high, low, close, volume, close time, quote asset volume, number of trades, taker buy base asset volume, taker buy quote asset volume, ignore
    df = pd.read_csv(io.BytesIO(csv_bytes), header=None)
    df.columns = ["open_time","open","high","low","close","volume","close_time","quote_vol","n_trades","tb_base","tb_quote","ignore"]
    unit = "us" if micros else "ms"
    df["datetime"] = pd.to_datetime(df["open_time"], unit=unit, utc=True)
    df = df.set_index("datetime")[["open","high","low","close","volume"]].astype(float).sort_index()
    return df

def fetch_month(symbol: str, interval: str, yyyy: int, mm: int, out_path: str):
    ensure_dir(os.path.dirname(out_path))
    fname = f"{symbol}-{interval}-{yyyy}-{mm:02d}.zip"
    url = BASE.format(freq="monthly", symbol=symbol, interval=interval) + fname
    url_checksum = url + ".CHECKSUM"

    zbytes = download(url)
    cbytes = download(url_checksum)
    if not verify_checksum(zbytes, cbytes.decode()):
        raise ValueError("Checksum µáíΘ¬îσñ▒Φ┤Ñ")

    with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:
        # µ»ÅΣ╕¬zipΘÇÜσ╕╕σîàσÉ½Σ╕ÇΣ╕¬csv
        csv_name = [n for n in zf.namelist() if n.endswith(".csv")][0]
        csv_bytes = zf.read(csv_name)
        # 2025-01-01 Φ╡╖τÄ░Φ┤ºΣ╕║σ╛«τºÆµù╢Θù┤µê│
        micros = (yyyy >= 2025)
        df = parse_kline_csv(csv_bytes, micros=micros)
        df.to_parquet(out_path)
        return df.index[0], df.index[-1], len(df)

if __name__ == "__main__":
    # τñ║Σ╛ï∩╝ÜΣ╕ïΦ╜╜ 2024σ╣┤/2025σ╣┤1m µò░µì«σ╣╢ΦÉ╜τ¢ÿ
    symbol = "BTCUSDT"
    interval = "1m"
    for y in [2024, 2025]:
        for m in range(1, 13):
            out = f"data/raw/exchange=binance/type=spot/symbol={symbol}/tf={interval}/{symbol}-{interval}-{y}-{m:02d}.parquet"
            try:
                s, e, n = fetch_month(symbol, interval, y, m, out)
                print(symbol, y, m, n, s, "->", e)
            except Exception as ex:
                print("Φ╖│Φ┐ç", symbol, y, m, ex)
```

Σ╕èΦ┐░Σ╕ïΦ╜╜Φ╖»σ╛äΣ╕Ä `CHECKSUM` τö¿µ│òπÇüµù╢Θù┤µê│σ╛«τºÆµö╣σè¿∩╝îσ¥çµ¥ÑΦç¬ Binance σà¼σæè/README∩╝¢σ«ÿµû╣Φ┐ÿτ╗ÖΣ║å `curl/wget` τñ║Σ╛ïσÆîΦäÜµ£¼τ¢«σ╜òπÇé([GitHub][2])

---

### A3. µ╕àµ┤ù∩╝êσÄ╗Θçì/σ»╣Θ╜É/µáíΘ¬î/ΦíÑτ⌐║µ┤₧∩╝ëµá╕σ┐âΣ╗úτáü

> Φªüτé╣∩╝Ü
>
> 1. **µù╢ΘÆƒτ╗ƒΣ╕Ç**∩╝êUTC∩╝ë∩╝îµ»½τºÆ/σ╛«τºÆΦç¬ΘÇéσ║ö∩╝¢
> 2. **σÄ╗ΘçìΣ╕ÄσìòΦ░âµÇº**∩╝¢
> 3. **OHLC σÉêµ│òµÇº**∩╝ê`high >= max(open,close)` Σ╕Ä `low <= min(open,close)`∩╝ë∩╝¢
> 4. **τ╝║σÅúµúÇµ╡ïΣ╕ÄΦªåτ¢ûτÄç**∩╝êσÅ¬σüÜµáçΦ«░µêûΦ░¿µàÄΦíÑσÇ╝∩╝ë∩╝¢
> 5. **µîëσêåσî║ΦÉ╜τ¢ÿ**∩╝ê`exchange/symbol/timeframe/YYYY=MM=...`∩╝ëµû╣Σ╛┐ DuckDB/Polars µë╣ΘçÅΦ»╗σÅûπÇé

```python
# scripts/clean_ohlcv.py
import os, glob
import pandas as pd
import numpy as np

def load_concat(pattern: str) -> pd.DataFrame:
    files = sorted(glob.glob(pattern))
    dfs = [pd.read_parquet(f) for f in files]
    df = pd.concat(dfs).sort_index()
    # τ╗ƒΣ╕ÇσêùΣ╕Äτ▒╗σ₧ï
    df = df[["open","high","low","close","volume"]].astype(float)
    # σÄ╗Θçì
    df = df[~df.index.duplicated(keep="last")]
    return df

def check_and_fix_ohlc(df: pd.DataFrame) -> pd.DataFrame:
    # Σ┐«µ¡úµÿÄµÿ╛τÜäΦ╢èτòî∩╝êµ₧üσ░æΦºü∩╝îσàêµáçΦ«░σåìΦúüσë¬∩╝ë
    maxoc = df[["open","close"]].max(axis=1)
    minoc = df[["open","close"]].min(axis=1)
    bad_hi = df["high"] < maxoc
    bad_lo = df["low"]  > minoc
    df.loc[bad_hi, "high"] = maxoc[bad_hi]
    df.loc[bad_lo, "low"]  = minoc[bad_lo]
    return df

def detect_gaps(df: pd.DataFrame, freq: str) -> pd.DataFrame:
    full = pd.date_range(df.index[0], df.index[-1], freq=freq, tz="UTC")
    missing = full.difference(df.index)
    coverage = 1 - len(missing)/len(full)
    print(f"Φªåτ¢ûτÄç: {coverage:.4%}∩╝îτ╝║σÅú: {len(missing)}")
    # µîëΘ£Ç∩╝ÜσÅ¬µáçΦ«░∩╝îΣ╕ìσ╝║Φíîσí½σàà
    return df

def save_partitioned(df: pd.DataFrame, base_dir: str, exchange: str, symbol: str, tf: str):
    # µîëµ£êσêåσî║
    df["YYYYMM"] = df.index.strftime("%Y-%m")
    for ym, g in df.groupby("YYYYMM"):
        out_dir = f"{base_dir}/exchange={exchange}/symbol={symbol}/tf={tf}/YYYYMM={ym}"
        os.makedirs(out_dir, exist_ok=True)
        g.drop(columns=["YYYYMM"]).to_parquet(f"{out_dir}/part.parquet")

if __name__ == "__main__":
    exchange = "binance"
    symbol = "BTCUSDT"     # µ│¿µäÅ∩╝ÜCCXT µÿ» "BTC/USDT"∩╝îBinance ZIP µÿ» "BTCUSDT"
    tf = "1m"
    # 1) σÉêσ╣╢ raw
    pattern = f"data/raw/exchange={exchange}/**/symbol={symbol.replace('/','-') or symbol}/tf={tf}/*.parquet"
    df = load_concat(pattern)
    # 2) σÉêµ│òµÇºΣ┐«µ¡ú & τ╝║σÅú
    df = check_and_fix_ohlc(df)
    df = detect_gaps(df, freq="1T")  # 1m
    # 3) ΦÉ╜τ¢ÿ∩╝êσêåσî║∩╝ë
    save_partitioned(df, base_dir="data/clean", exchange=exchange, symbol=symbol.replace('/','-'), tf=tf)
```

**Σ╕║Σ╗ÇΣ╣êµ£ÇσÉÄΣ╕Çµá╣Kτ║┐ΦªüΦ░¿µàÄσñäτÉå∩╝ƒ**
CCXT µûçµíúΦ»┤µÿÄΓÇ£µ£ÇσÉÄ∩╝êσ╜ôσëì∩╝ëK τ║┐σ£¿µ£¬µö╢τ¢ÿσëìΣ┐íµü»σÅ»Φâ╜Σ╕ìσ«îµò┤ΓÇ¥∩╝îµëÇΣ╗Ñσ¢₧µ╡ïµù╢σ╗║Φ««Σ╗àΣ╜┐τö¿**σ╖▓µö╢τ¢ÿ**τÜä K τ║┐∩╝êµêæΣ╗¼σ╖▓σ£¿µïëσÅûµù╢σëöΘÖñ∩╝ëπÇé([CCXT Documentation][1])

---

## Θÿ╢µ«╡ B∩╝Üτö¿µ╕àµ┤ùσÉÄτÜäµò░µì«**µ₧äσ╗║σ«îµò┤σ¢₧µ╡ï**

> µêæΣ╗¼τö¿ `vectorbt` µîëΣ┐íσÅ╖σ¢₧µ╡ïπÇéΦ»Ñσ║ôτÜä `Portfolio.from_signals`∩╝Ü
>
> * τ¢┤µÄÑµÄÑσÅù `fees`∩╝êΦ┤╣τÄç∩╝ëΣ╕Ä `slippage`∩╝êµ╗æτé╣∩╝ë∩╝¢
> * σÄƒτöƒσåàτ╜«**µ¡óµìƒ/µ¡óτ¢ê/Φ┐╜Φ╕¬µ¡óµìƒ**τ¡ë∩╝ê`sl_stop`/`tp_stop`/`ts_stop` τ¡ëσÅéµò░∩╝ë∩╝¢
> * σ«ÿµû╣µûçµíúµÅÉσê░ΓÇ£σ«₧τÄ░µ¡óµìƒΣ╕Äµ¡óτ¢êΘÇÇσç║ΓÇ¥∩╝¢σ╕╕ΦºüµòÖτ¿ïΣ╣ƒµ╝öτñ║Σ║å `sl_stop` Σ╕Ä `tp_stop` τÜäτö¿µ│ò∩╝êτÖ╛σêåµ»ö∩╝ëπÇé([VectorBT][3])

### B1. Φ»╗µò░Σ╕Äσ»╣Θ╜É

```python
# backtests/vbt_ma_rsi.py (τëçµ«╡)
import duckdb, polars as pl
import pandas as pd
import numpy as np
import vectorbt as vbt

# Φ»╗σàÑσêåσî║µò░µì«∩╝êDuckDB/Polars Θ¥₧σ╕╕σ┐½∩╝ë
con = duckdb.connect()
tbl = con.execute("""
    SELECT *
    FROM read_parquet('data/clean/exchange=binance/symbol=BTCUSDT/tf=1m/**/part.parquet')
    ORDER BY datetime
""").pl()  # -> Polars DataFrame
df = tbl.to_pandas()
df.index = pd.to_datetime(df["datetime"], utc=True)
close = df["close"].astype(float)
```

### B2. τñ║Σ╛ïτ¡ûτòÑ∩╝ÜMA Σ║ñσÅë + RSI Φ┐çµ╗ñ∩╝êσÉ½σÅéµò░τ╜æµá╝∩╝ë

```python
# Φ«íτ«ùΣ┐íσÅ╖
fast_list = np.arange(5, 51, 5)    # 5,10,...,50
slow_list = np.array([50, 100, 200])
rsi_n = np.array([14, 21])

fast_ma = vbt.MA.run(close, fast_list, short_name="fast")
slow_ma = vbt.MA.run(close, slow_list, short_name="slow")
rsi = vbt.RSI.run(close, rsi_n, short_name="rsi")

entries = (fast_ma.ma_crossed_above(slow_ma)) & (rsi.rsi < 70)  # Σ╕èτ⌐┐ + Σ╕ìΦ┐çτâ¡
exits   = (fast_ma.ma_crossed_below(slow_ma)) | (rsi.rsi > 80)  # Σ╕ïτ⌐┐ µêû Φ┐çτâ¡
```

`vbt.MA.run` Σ╕Ä `Portfolio.from_signals` τÜäσàÑΘù¿τñ║Σ╛ïσ£¿σ«ÿµû╣ΓÇ£Usage/FeaturesΓÇ¥µûçµíúΣ╕¡µ╕àµÖ░σ▒òτñ║∩╝êσîàµï¼ `size=np.inf, fees=...` τÜäσà╕σ₧ïτö¿µ│ò∩╝ëπÇé([VectorBT][6])

### B3. µêÉµ£¼πÇüµ╗æτé╣πÇüµ¡óµìƒ/µ¡óτ¢êπÇüΦ╡äΘçæτ«íτÉåΣ╕ÄΘóæτÄçΦ«╛σ«Ü

```python
# σƒ║τíÇσüçΦ«╛∩╝êΦ»╖µîëσ«₧ΘÖàΣ║ñµÿôµëÇΦ┤╣τÄçΦ░âµò┤∩╝¢Binance τÄ░Φ┤ºσ╕╕ΦºüΘ╗ÿΦ«ñ ~0.1%∩╝ë
init_cash   = 100_000
fees        = 0.001     # 0.1% µëïτ╗¡Φ┤╣∩╝êτñ║Σ╛ï∩╝îσ╗║Φ««τö¿Θàìτ╜«Θí╣∩╝ë
slippage    = 0.0002    # 2Σ╕¬σƒ║τé╣τñ║Σ╛ï
sl_stop     = 0.02      # σàÑσ£║Σ╗╖Σ╕ïµû╣ 2% µ¡óµìƒ
tp_stop     = 0.04      # σàÑσ£║Σ╗╖Σ╕èµû╣ 4% µ¡óτ¢ê

pf = vbt.Portfolio.from_signals(
    close,
    entries=entries,
    exits=exits,
    init_cash=init_cash,
    size=np.inf,          # µ╗íΣ╗ôσêåΘàì∩╝îµ»Åµ¼íµèèσÅ»τö¿τÄ░Θçæσà¿µèòσàÑ∩╝êσ«ÿµû╣τñ║Σ╛ïσ╕╕τö¿µ│ò∩╝ë
    fees=fees,
    slippage=slippage,
    sl_stop=sl_stop,
    tp_stop=tp_stop,
    freq="1T"             # 1σêåΘÆƒΘóæτÄç -> σ╣┤σîûτ¡ëτ╗ƒΦ«í
)
print(pf.stats())
```

* `from_signals` σÄƒτöƒµö»µîü `fees`/`slippage` σ╣╢σ«₧τÄ░µ¡óµìƒ/µ¡óτ¢ê∩╝êµûçµíúµîçσç║∩╝ëπÇé([VectorBT][3])
* `size=np.inf` τÜäτñ║Σ╛ïΘàìτ╜«σÅ»σ£¿σ«ÿµû╣ΓÇ£UsageΓÇ¥Θí╡Θ¥óτ£ïσê░πÇé([VectorBT][6])
* Φ┤╣τÄçσÅéµò░σ╗║Φ««σÅéΦÇâΣ║ñµÿôµëÇσ«₧ΘÖàΦ┤╣τÄçΘí╡Θ¥ó∩╝êσªé Binance Φ┤╣τÄçΘí╡/FAQ Σ╕╛Σ╛ï 0.1%∩╝ëπÇé([Binance][4])

### B4. Φ«¡τ╗â/µ╡ïΦ»òµïåσêåΣ╕ÄΦ╡░µá╖∩╝êWalkΓÇæForward∩╝ë

```python
split_dt = pd.Timestamp("2023-01-01", tz="UTC")
close_train = close[close.index < split_dt]
close_test  = close[close.index >= split_dt]

# Φ«¡τ╗â∩╝ÜσÅéµò░µÉ£τ┤ó∩╝êσê⌐τö¿σ╣┐µÆ¡Σ╕Çµ¼íµÇºΦ╖æσñÜτ╗äσÅéµò░∩╝ë
fast_ma_tr = vbt.MA.run(close_train, fast_list)
slow_ma_tr = vbt.MA.run(close_train, slow_list)
rsi_tr     = vbt.RSI.run(close_train, rsi_n)

entries_tr = (fast_ma_tr.ma_crossed_above(slow_ma_tr)) & (rsi_tr.rsi < 70)
exits_tr   = (fast_ma_tr.ma_crossed_below(slow_ma_tr)) | (rsi_tr.rsi > 80)

pf_tr = vbt.Portfolio.from_signals(close_train, entries_tr, exits_tr,
                                   init_cash=init_cash, size=np.inf, fees=fees,
                                   slippage=slippage, sl_stop=sl_stop, tp_stop=tp_stop, freq="1T")
train_stats = pf_tr.stats()
# ΘÇëµï⌐ΦïÑσ╣▓µîçµáçµ£ÇΣ╝ÿτÜäσÅéµò░∩╝êσªé Sharpe / Calmar / µ£Çσñºσ¢₧µÆñτ║ªµ¥ƒτ¡ë∩╝ë
best = train_stats.sort_values("Sharpe Ratio", ascending=False).index[0]
print("Φ«¡τ╗âµ£ƒµ£ÇΣ╝ÿσÅéµò░∩╝Ü", best)

# µ╡ïΦ»ò∩╝Üτö¿τ¢╕σÉîσÅéµò░σ£¿ OOS Σ╕èΘ¬îΦ»ü
#∩╝êτ«ÇσìòσüÜµ│ò∩╝ÜσÅûσ»╣σ║öσêù∩╝¢Σ╣ƒσÅ»µèè entries/exits σ£¿ test Σ╕èτö¿τ¢╕σÉî n Θçìµû░Φ«íτ«ùΣ╕Çµ¼í∩╝ë
fast_n = best[best.index("fast_window") if "fast_window" in best else 0]  # Σ╝¬Σ╗úτáü∩╝îσ«₧ΘÖàµîëσñÜτ║ºτ┤óσ╝òσÅû
slow_n = ...
rsi_n_ = ...
# Θçìµû░Φ«íτ«ù test Σ┐íσÅ╖∩╝êτòÑ∩╝ë
# pf_te = vbt.Portfolio.from_signals(close_test, entries_te, exits_te, ...)

# σñÜµèÿΦ╡░µá╖/µ╗Üσè¿τ¬ùσÅúσÅ»σåìσ░üΦúà
```

> Φ»┤µÿÄ∩╝Ü`vectorbt` τÜäσ╣┐µÆ¡Φâ╜σè¢σÅ»Σ╕Çµ¼íµÇºΦ╖æσñºΘçÅσÅéµò░τ╗äσÉê∩╝¢µòÖτ¿ï/τñ║Σ╛ïµûçτ½áΣ╣ƒµ╝öτñ║Σ║åσ£¿ `from_signals` ΘçîΣ╝á `fees`πÇü`slippage` σ╣╢Φ┐¢ΦíîΦ╡░µá╖Θ¬îΦ»üπÇé([VectorBT][6])

### B5. ΘúÄΘÖ⌐Σ╕Äτ╗åΦèéσñäτÉåµ╕àσìò

* **Σ╗àτö¿σ╖▓µö╢τ¢ÿ K τ║┐**∩╝îΘü┐σàìΣ╜┐τö¿ΓÇ£µ┤╗σè¿Σ╕¡ΓÇ¥τÜäµ£ÇσÉÄΣ╕Çµá╣∩╝¢CCXT µûçµíúµÅÉτñ║µ£¬µö╢σ«îτÜä K τ║┐σÅ»Φâ╜Σ╕ìσ«îµò┤πÇé([CCXT Documentation][1])
* **Φ┤╣τÄç/µ╗æτé╣**∩╝ÜµîëΣ║ñµÿôµëÇσ╜ôΣ╕ïΦ┤╣τÄçΦ«╛σ«Ü∩╝êBinance τÄ░Φ┤ºσÅéΦÇâΘ╗ÿΦ«ñ 0.1%∩╝ë∩╝¢Σ╕ìσÉîσ╕éσ£║/Φ┤ªµê╖σ▒éτ║ºΣ╝ÜσÅÿσîûπÇé([Binance][4])
* **µò░µì«µù╢Θù┤µê│**∩╝ÜBinance τÄ░Φ┤º 2025ΓÇæ01ΓÇæ01 Φ╡╖Σ╜┐τö¿**σ╛«τºÆ**∩╝¢Φºúµ₧Éµù╢Φ»╖σî║σêåµ»½τºÆ/σ╛«τºÆπÇé([GitHub][2])
* **τ╝║σÅúΣ╕ÄΦªåτ¢ûτÄç**∩╝Üσ»╣ 24/7 σ╕éσ£║Σ╣ƒσÅ»Φâ╜µ£ë API ΘÖÉµ╡ü/Σ╕¡µû¡σ»╝Φç┤τÜäτ⌐║µ┤₧∩╝¢σ╗║Φ««σ£¿µèÑσæèΣ╕¡Φ╛ôσç║**Φªåτ¢ûτÄç**σ╣╢σ»╣τ╝║σÅúµ«╡σüÜΓÇ£τªüτö¿Σ║ñµÿôΓÇ¥µêûΓÇ£Φ░¿µàÄσëìσÇ╝σí½σààΓÇ¥τÜäσ»╣τàºΦ»òΘ¬îπÇé
* **σñÜΣ║ñµÿôµëÇ/σñÜΣ║ñµÿôσ»╣**∩╝Üτ╗ƒΣ╕Ç UTCπÇüσêùσÉìΣ╕Äσêåσî║σæ╜σÉì∩╝¢τö¿ DuckDB/Polars µë╣ΘçÅµï╝µÄÑσ╣╢µîëµ£Çτ╗åσæ¿µ£ƒσ»╣Θ╜ÉσÉÄσåìσ¢₧µ╡ïπÇé
* **τÄ░Φ┤º vs µ░╕τ╗¡**∩╝Üµ£¼µû╣µíêΣ╗Ñ**τÄ░Φ┤º**Σ╕║Σ╛ï∩╝¢ΦïÑτö¿µ░╕τ╗¡σÉêτ║ª∩╝îΦ┐ÿΘ£ÇΦÇâΦÖæ**Φ╡äΘçæΦ┤╣τÄç**πÇüµ¥áµ¥åΣ╕èΘÖÉΣ╕Äσ╝║σ╣│τ║┐µ¿íµïƒπÇé
* **σ«₧τ¢ÿσüÅσ╖«**∩╝Üσ¢₧µ╡ïΘ╗ÿΦ«ñΓÇ£Σ╕ïΣ╕Çµá╣σ╝Çτ¢ÿµêÉΣ║ñ/µö╢τ¢ÿµêÉΣ║ñΓÇ¥τÜäµÆ«σÉêτ«Çσîû∩╝îΣ╝ÜΣ╜ÄΣ╝░τ£ƒσ«₧µ╗æτé╣∩╝¢σÅ»µÅÉΘ½ÿ `slippage` σ╣╢Φ┐¢ΦíîµòÅµäƒµÇºσêåµ₧ÉπÇé

---

## Σ╕ÇΘö«µëºΦíîµ¡ÑΘ¬ñ∩╝êΣ╗Ä 0 σê░σ¢₧µ╡ï∩╝ë

1. **Θàìτ╜«**∩╝ÜΣ┐«µö╣ `conf/symbols.yaml`∩╝êΣ║ñµÿôµëÇπÇüσôüτºìπÇüσæ¿µ£ƒπÇüµù╢Θù┤∩╝ëπÇé
2. **Σ╕ïΦ╜╜µò░µì«**∩╝Ü

   * Φ┐æσ«₧µù╢∩╝Ü`python scripts/fetch_ccxt_ohlcv.py --conf conf/symbols.yaml`∩╝êCCXT `fetch_ohlcv`∩╝îσêåΘí╡µèôσÅû∩╝ëπÇéσà│Σ║Ä `fetch_ohlcv` τÜäτ╗ƒΣ╕Çτ╗ôµ₧äΣ╕Äµ│¿µäÅΣ║ïΘí╣Φºü CCXT µëïσåîπÇé([CCXT Documentation][1])
   * σÄåσÅ▓µë╣ΘçÅ∩╝êσÅ»ΘÇë/ΦíÑΘ╜É∩╝ë∩╝Ü`python scripts/fetch_binance_bulk.py`∩╝êBinance Data Vision∩╝îσ╕ª CHECKSUM Σ╕Ä 2025 σ╛«τºÆµù╢Θù┤µê│∩╝ëπÇé([GitHub][2])
3. **µ╕àµ┤ùΦÉ╜τ¢ÿ**∩╝Ü`python scripts/clean_ohlcv.py`∩╝êσÄ╗Θçì/µáíΘ¬î/Φªåτ¢ûτÄç/µîëµ£êσêåσî║∩╝ëπÇé
4. **σ¢₧µ╡ï**∩╝Ü`python backtests/vbt_ma_rsi.py`∩╝êσÉ½Φ┤╣τÄç/µ╗æτé╣/µ¡óµìƒµ¡óτ¢ê/σÅéµò░τ╜æµá╝/σêåσë▓Θ¬îΦ»ü∩╝ëπÇé`from_signals` σ»╣µ¡óµìƒ/µ¡óτ¢ê/Φ┤╣τö¿/µ╗æτé╣τÜäµö»µîüΦºüσ«ÿµû╣µûçµíúτñ║Σ╛ïΣ╕ÄµÅÅΦ┐░πÇé([VectorBT][3])

---

## σÅ»µë⌐σ▒òσ╗║Φ««

* **µò░µì«µ╣ûτ╗äτ╗ç**∩╝ÜΣ╜┐τö¿ `data/clean/exchange=.../symbol=.../tf=.../YYYYMM=...` τÜäσêåσî║τ╗ôµ₧ä∩╝îDuckDB Σ╕Çµ¥í SQL σì│σÅ»Φ╖¿σ╣┤µ£ƒπÇüΦ╖¿σñÜµáçτÜäµï╝µÄÑΦüÜσÉêπÇé
* **µîçµáçσ║ô**∩╝Ü`pandas_ta`/`vectorbt` Φç¬σ╕ªµîçµáçΦ╢│σñƒΣ╕░σ»î∩╝¢Σ╣ƒσÅ»σ░üΦúàΣ╜áΦç¬σ╖▒τÜä alpha τë╣σ╛üπÇé
* **σñÜτ¡ûτòÑ/σñÜΦ╡äΣ║ºτ╗äσÉê**∩╝Ü`vectorbt` τÜäσ╣┐µÆ¡Σ╕Ä `MetaPortfolio` Φâ╜σ┐½ΘÇƒσüÜσñÜΦ╡äΣ║ºσ¢₧µ╡ïΣ╕Äτ╗äσÉêΣ╝ÿσîûπÇéµûçµíú API σêùΦí¿Σ║ªΦªåτ¢ûσ╕╕Φºüτ╗⌐µòêµîçµáç∩╝êSharpe/Sortino/σ¢₧µÆñτ¡ë∩╝ëπÇé([VectorBT][3])
* **τöƒΣ║ºσîû**∩╝Ü

  * Φ«íσêÆΣ╗╗σèí∩╝êcron∩╝ëσüÜ**σó₧ΘçÅµ¢┤µû░**∩╝êµ»Åσ░Åµù╢/µ»ÅµùÑ∩╝ë∩╝îΦ»╗σÅûσ╖▓µ£ëµò░µì«τÜäµ£ÇσÉÄµù╢Θù┤µê│Σ╕║Φ╡╖τé╣τ╗¡µïë∩╝¢
  * µò░µì«Φ┤¿ΘçÅµèÑσæè∩╝êτ╝║σÅúπÇüµ₧üσÇ╝πÇüσ╝éσ╕╕Φ╖│σÅÿ∩╝ëσàÑσ║ôσ╣╢σæèΦ¡ª∩╝¢
  * σ¢₧µ╡ïτ╗ôµ₧£∩╝êσÅéµò░πÇüτ╗⌐µòêπÇüµ¢▓τ║┐∩╝ëΣ╕Äµò░µì«τëêµ£¼**τ╗æσ«Ü**∩╝êΣ╛┐Σ║Äσ«íΦ«íΣ╕ÄσñìτÄ░∩╝ëπÇé

---

## σ░Åτ╗ô

* **µò░µì«σ▒é**∩╝ÜΣ╕ñτºìµ¥Ñµ║É∩╝êCCXT σ«₧µù╢µïëσÅû + Binance µë╣ΘçÅΣ╕ïΦ╜╜∩╝ëσ¥çΣ╕║**σ«ÿµû╣µêûΣ╕Üτòîµáçσçå**σüÜµ│ò∩╝¢σà╢Σ╕¡ `fetch_ohlcv` τÜäτ╗ôµ₧äπÇüµ£ÇσÉÄ K τ║┐Σ╕ìσ«îµò┤τ¡ëµ│¿µäÅΣ║ïΘí╣πÇüΣ╗ÑσÅè Binance 2025 Φ╡╖σ╛«τºÆµù╢Θù┤µê│τ¡ëσ¥çµ£ëσ«ÿµû╣µûçµíú/README Σ╜£Σ╕║Σ╛¥µì«πÇé([CCXT Documentation][1])
* **σ¢₧µ╡ïσ▒é**∩╝Ü`vectorbt` Σ╗ÑΣ┐íσÅ╖Σ╕║Σ╕¡σ┐â∩╝î**σåàτ╜«Φ┤╣τö¿/µ╗æτé╣/µ¡óµìƒµ¡óτ¢ê**∩╝îσ╣╢µ£ëσ«ÿµû╣µûçµíúΣ╕Äτñ║Σ╛ïµö»µÆæ∩╝¢σÅ»µë⌐σ▒òσê░σÅéµò░µÉ£τ┤óΣ╕ÄΦ╡░µá╖Θ¬îΦ»üπÇé([VectorBT][3])

> Σ╗ÑΣ╕èΣ╗úτáüσÅ»τ¢┤µÄÑσñìσê╢σê░σ»╣σ║öµûçΣ╗╢Φ┐ÉΦíî∩╝¢ΦïÑΣ╜áΘ£ÇΦªüµêæ**µ¢┐Σ╜áµèèΦ┐ÖσÑùΘ¬¿µ₧╢Φúüσë¬µêÉΣ╜áµîçσ«ÜΣ║ñµÿôµëÇ/σôüτºì/τ¡ûτòÑτÜäµ£Çσ░ÅσÅ»µëºΦíîµ¿íµ¥┐**∩╝îµêæσÅ»Σ╗Ñσ£¿Σ╕ïΣ╕Çµ¡ÑΣ╕Çµ¼íµÇºτ╗Öσç║σ«îµò┤Σ╗ôσ║ôτ╗ôµ₧ä∩╝êσÉ½ `requirements.txt` Σ╕Äτñ║Σ╛ïµò░µì«/σ¢₧µ╡ïτ╗ôµ₧£∩╝ëπÇé**ΘúÄΘÖ⌐µÅÉτñ║**∩╝ÜµëÇµ£ëτñ║Σ╛ïΣ╗àΣ╕║µèÇµ£»Σ╕Äτáöτ⌐╢τö¿ΘÇö∩╝îΣ╕ìµ₧äµêÉµèòΦ╡äσ╗║Φ««πÇé

[1]: https://ccxtcn.readthedocs.io/zh_CN/latest/manual.html?utm_source=chatgpt.com "Overview ΓÇö ccxt 1.13.142 µûçµíú"
[2]: https://github.com/binance/binance-public-data "GitHub - binance/binance-public-data: Details on how to get Binance public data"
[3]: https://vectorbt.dev/api/portfolio/base/ "base - vectorbt"
[4]: https://www.binance.com/en/fee/schedule?utm_source=chatgpt.com "Spot Trading Fee Rate"
[5]: https://github.com/ccxt/ccxt/wiki/manual?utm_source=chatgpt.com "Manual ┬╖ ccxt/ccxt Wiki"
[6]: https://vectorbt.dev/getting-started/usage/?utm_source=chatgpt.com "Usage"
